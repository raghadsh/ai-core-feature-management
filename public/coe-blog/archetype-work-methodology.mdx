---
title: "Your Mission in the Archetype Work"
author: "AI CoE Team"
date: "2024-01-14"
category: "Methodology"
excerpt: "A scientific, evidence-based approach to evaluating how well ai core serves the most important recurring tasks (the archetypes)."
---

# Your Mission in the Archetype Work

## Core Principles

- **Be Scientific**: Treat each archetype as a research question.
- **Be Critical**: We don't just say "it works" or "it fails" â€” we explain why.
- **Be Practical**: Always connect insights back to concrete improvements (what can we do next?).

## Our Approach

Our job is to follow a scientific, evidence-based approach to figure out how well ai core serves the most important recurring tasks (the archetypes). That means:

## 1. Define the Question Clearly

**Example**: "Is ai core good at doing benchmarking using web search and other file sources?"

**Or**: "How consistently does ai core retrieve accurate data from structured files?"

## 2. Design a Test/Evaluation

- Collect sample cases (synthetic and real from business users).
- Run them systematically through ai core (and later compare to baselines if needed).

## 3. Analyze the Results

- Measure success (accuracy, completeness, user satisfaction, efficiency).
- Identify common failure points (hallucinations, missing context, formatting issues, etc.).

## 4. Frame Insights as Problems + Hypotheses

This is the diagnosis step.

- **Problem**: What's going wrong, observed in the evaluation.
- **Hypothesis**: Why it's happening (a guess rooted in logic/experience).

### Example

- **Problem**: "ai core struggles with multi-document comparison."
- **Hypothesis**: "Adding retrieval grounding or fine-tuning on comparison data could help."

## 5. Propose Solution Paths

Here you take the hypothesis and suggest ways to fix it.

- **Quick fixes** (prompting strategies).
- **Medium fixes** (agent design, workflow redesign, tool integration).
- **Long fixes** (fine-tuning, data curation, evaluation dataset expansion).

---

*This methodology ensures we maintain a rigorous, evidence-based approach to improving ai core's performance across all critical use cases.*
